package main

import (
	"fmt"
	"net/http"
	"os"
	"strings"
	"time"

	"github.com/gocolly/colly"
)

type Link struct {
	Text    string // —Ç–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏
	URL     string // –≤–Ω–µ—à–Ω—è—è —Å—Å—ã–ª–∫–∞
	PageURL string // URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–∞–π—Ç–∞, –≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω–µ—à–Ω—è—è —Å—Å—ã–ª–∫–∞
	Error   string // –¢–µ–∫—Å—Ç –æ—à–∏–±–∫–∏
}

var externalLinks = []*Link{}

func main() {
	// Instantiate default collector
	c := colly.NewCollector(
		// Visit only domains:
		colly.AllowedDomains("hazadus.ru"),
	)

	// On every a element which has href attribute call callback
	c.OnHTML("a[href]", func(e *colly.HTMLElement) {
		link := e.Attr("href")

		// –°—Å—ã–ª–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è –Ω–µ —Å https://hazadus.ru, https://amgold.ru, mailto:,
		// –¥–æ–±–∞–≤–ª—è—Ç—å –≤ –º–∞—Å—Å–∏–≤
		if isExternalLink(link) {
			fmt.Printf("    –ù–∞–π–¥–µ–Ω–∞ –≤–Ω–µ—à–Ω—è—è —Å—Å—ã–ª–∫–∞: %q -> %s\n", e.Text, link)
			addExternalLink(&Link{
				Text:    e.Text,
				URL:     link,
				PageURL: e.Request.URL.String(),
			})
		}

		// Visit link found on page
		// Only those links are visited which are in AllowedDomains
		c.Visit(e.Request.AbsoluteURL(link))
	})

	// Before making a request print "Visiting ..."
	c.OnRequest(func(r *colly.Request) {
		fmt.Println("Visiting", r.URL.String())
	})

	// Start scraping
	c.Visit("https://hazadus.ru/")

	// –í–Ω–µ—à–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –≤ –º–∞—Å—Å–∏–≤–µ –æ–±–æ–π—Ç–∏, –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å —É—Å–ø–µ—Ö/–Ω–µ—É—Å–ø–µ—Ö
	// –ù–µ—É—Å–ø–µ—à–Ω—ã–µ –¥–æ–±–∞–≤–∏—Ç—å –≤ –º–∞—Å—Å–∏–≤ broken
	var brokenLinks = []*Link{}
	for i, l := range externalLinks {
		fmt.Printf("%d. %q - %s\n", i+1, l.Text, l.URL)

		ok, err := checkStatusAndRedirects(l.URL)
		if !ok {
			if err != nil {
				fmt.Printf("    –û—à–∏–±–∫–∞: %s\n    @ %q\n", err.Error(), l.PageURL)
				l.Error = err.Error()
			} else {
				fmt.Printf("    –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å URL\n    @ %q\n", l.PageURL)
			}

			brokenLinks = append(brokenLinks, l)
		}
	}

	err := createMarkdownReport(brokenLinks, "./report.md")
	if err != nil {
		fmt.Printf("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ—Ç—á–µ—Ç–∞: %s\n", err)
		os.Exit(1)
	}
}

func isExternalLink(url string) bool {
	return strings.HasPrefix(url, "http") &&
		(!strings.HasPrefix(url, "https://hazadus.ru") || !strings.HasPrefix(url, "https://amgold.ru") || !strings.HasPrefix(url, "mailto:"))
}

func addExternalLink(link *Link) {
	for _, l := range externalLinks {
		if l.URL == link.URL {
			return
		}
	}

	externalLinks = append(externalLinks, link)
}

func checkStatusAndRedirects(url string) (bool, error) {
	var redirectCount int
	nextURL := url
	maxRedirectsAllowed := 100
	getRequestTimeout := 3 * time.Second

	// –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤
	for redirectCount <= maxRedirectsAllowed {
		httpClient := http.Client{
			Timeout: getRequestTimeout,
			CheckRedirect: func(req *http.Request, via []*http.Request) error {
				return http.ErrUseLastResponse
			},
		}

		response, err := httpClient.Get(nextURL)
		if err != nil {
			return false, err
		}
		if response.StatusCode == 200 {
			return true, nil
		} else {
			nextURL = response.Header.Get("Location")
			redirectCount += 1
		}
	}

	return false, nil
}

func createMarkdownReport(brokenLinks []*Link, outputFilePath string) error {
	report := fmt.Sprintf("# ‚õìÔ∏è‚Äçüí• –ë–∏—Ç—ã–µ —Å—Å—ã–ª–∫–∏\n\n–í—Å–µ–≥–æ: %d\n", len(brokenLinks))

	for i, l := range brokenLinks {
		report += fmt.Sprintf("\n## %d. –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ %s\n\n- ‚å®Ô∏è –¢–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏: %q\n- ‚õìÔ∏è‚Äçüí• –í–Ω–µ—à–Ω–∏–π URL: %s\n- ‚ö†Ô∏è –û—à–∏–±–∫–∞: %s\n",
			i+1,
			l.PageURL,
			l.Text,
			l.URL,
			l.Error,
		)
	}

	return os.WriteFile(outputFilePath, []byte(report), 0644)
}
